@article{Schmalzried.2023.AdRKIfemI50,
 author = {Schmalzried, Dirk and Hurst, Marco and Wentzien, Marcel and Gr{\"a}ser, Max},
 year = {2023},
 title = {Analyse der Rolle K{\"u}nstlicher Intelligenz f{\"u}r eine menschenzentrierte Industrie 5.0},
 pages = {1143--1155},
 volume = {60},
 number = {6},
 issn = {1436-3011},
 journal = {HMD Praxis der Wirtschaftsinformatik},
 doi = {10.1365/s40702-023-01001-y}
}



@article{Wentzien.2024.MLBPotMST,
 author = {Wentzien, Marcel and Koch, Marcel and Friedrich, Thomas and Ingber, Jerome and Kempka, Henning and Schmalzried, Dirk and Kunert, Maik},
 year = {2024},
 title = {Machine Learning--Based Prediction of the Martensite Start Temperature},
 volume = {95},
 number = {10},
 issn = {1611-3683},
 journal = {Steel Research International},
 doi = {10.1002/srin.202400210}
}


@inproceedings{Wentzien.2025.CtVQoDGMfSM,
 author = {Wentzien, Marcel and Ingber, Jerome and Schl{\"o}tterer, J{\"o}rg and Schmalzried, Dirk},
 title = {Comparing the Visual Quality of Deep Generative Models for Steel Microstructures},
 pages = {278--285},
 publisher = {{Springer Nature Switzerland}},
 isbn = {978-3-032-02813-6},
 editor = {Braun, Tanya and Paa{\ss}en, Benjamin and Stolzenburg, Frieder},
 booktitle = {KI 2025: Advances in Artificial Intelligence},
 year = {2025},
 address = {Cham},
 doi = {10.1007/978-3-032-02813-6{\textunderscore }23}
}

@InProceedings{Joseph:2024:ACL,
  title         = {{F}act{PICO}: {F}actuality Evaluation for Plain Language Summarization of Medical
                  Evidence},
  author        = {Joseph, Sebastian and Chen, Lily and Trienes, Jan and G{\"o}ke, Hannah and Coers,
                  Monika and Xu, Wei and Wallace, Byron and Li, Junyi Jessy},
  booktitle     = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers)},
  month         = aug,
  year          = {2024},
  publisher     = {Association for Computational Linguistics},
  url           = {https://aclanthology.org/2024.acl-long.459},
  pages         = {8437--8464}
}

@inproceedings{Sarumi2024_naacl_annotator-modelling,
    title = "Corpus Considerations for Annotator Modeling and Scaling",
    author = {Sarumi, Olufunke O.  and
      Neuendorf, B{\'e}la  and
      Plepi, Joan  and
      Flek, Lucie  and
      Schl{\"o}tterer, J{\"o}rg  and
      Welch, Charles},
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.59",
    doi = "10.18653/v1/2024.naacl-long.59",
    pages = "1029--1040",
    abstract = "Recent trends in natural language processing research and annotation tasks affirm a paradigm shift from the traditional reliance on a single ground truth to a focus on individual perspectives, particularly in subjective tasks. In scenarios where annotation tasks are meant to encompass diversity, models that solely rely on the majority class labels may inadvertently disregard valuable minority perspectives. This oversight could result in the omission of crucial information and, in a broader context, risk disrupting the balance within larger ecosystems. As the landscape of annotator modeling unfolds with diverse representation techniques, it becomes imperative to investigate their effectiveness with the fine-grained features of the datasets in view. This study systematically explores various annotator modeling techniques and compares their performance across seven corpora. From our findings, we show that the commonly used user token model consistently outperforms more complex models. We introduce a composite embedding approach and show distinct differences in which model performs best as a function of the agreement with a given dataset. Our findings shed light on the relationship between corpus statistics and annotator modeling performance, which informs future work on corpus construction and perspectivist NLP.",
}

@inproceedings{Nguyen2022_aistats_important_fraud,
  title = 	 { The Importance of Future Information in Credit Card Fraud Detection },
  author =       {Bach Nguyen, Van and Ghosh Dastidar, Kanishka and Granitzer, Michael and Siblini, Wissam},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {10067--10077},
  year = 	 {2022},
  editor = 	 {Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/bach-nguyen22a/bach-nguyen22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/bach-nguyen22a.html},
  abstract = 	 { Fraud detection systems (FDS) mainly perform two tasks: (i) real-time detection while the payment is being processed and (ii) posterior detection to block the card retrospectively and avoid further frauds. Since human verification is often necessary and the payment processing time is limited, the second task manages the largest volume of transactions. In the literature, fraud detection challenges and algorithms performance are widely studied but the very formulation of the problem is never disrupted: it aims at predicting if a transaction is fraudulent based on its characteristics and the past transactions of the cardholder. Yet, in posterior detection, verification often takes days, so new payments on the card become available before a decision is taken. This is our motivation to propose a new paradigm: posterior fraud detection with "future" information. We start by providing evidence of the on-time availability of subsequent transactions, usable as extra context to improve detection. We then design a Bidirectional LSTM to make use of these transactions. On a real-world dataset with over 30 million transactions, it achieves higher performance than a regular LSTM, which is the state-of-the-art classifier for fraud detection that only uses the past context. We also introduce new metrics to show that the proposal catches more frauds, more compromised cards, and based on their earliest frauds. We believe that future works on this new paradigm will have a significant impact on the detection of compromised cards. }
}

@InProceedings{Trienes:2019:ECIR,
  author        = {Trienes, Jan and Balog, Krisztian},
  title         = {Identifying Unclear Questions in Community Question Answering Websites},
  booktitle     = {Advances in Information Retrieval},
  year          = {2019},
  pages         = {276--289},
  doi           = {10.1007/978-3-030-15712-8_18}
}

@InProceedings{Trienes:2018:DIR,
  author        = {Trienes, Jan and Cano, Andr√©s Torres and Hiemstra, Djoerd},
  title         = {Recommending Users: {W}hom to Follow on Federated Social Networks},
  booktitle     = {Proceedings of the 17th Dutch-Belgian Information Retrieval Workshop (DIR)},
  year          = {2018},
  url           = {https://arxiv.org/abs/1811.09292}
}

@inproceedings{Sarumi:2025:Comedi,
    title = "Funzac at {C}o{M}e{D}i Shared Task: Modeling Annotator Disagreement from Word-In-Context Perspectives",
    author = {Sarumi, Olufunke O. and Welch, Charles and Flek, Lucie and Schl{\"o}tterer, J{\"o}rg},
    editor = "Roth, Michael and Schlechtweg, Dominik",
    booktitle = "Proceedings of Context and Meaning: Navigating Disagreements in NLP Annotation",
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2025.comedi-1.8/",
    pages = "90--96"
}

