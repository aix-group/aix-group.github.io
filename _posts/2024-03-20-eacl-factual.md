---
title: "'The Queen of England is not Englandâ€™s Queen.' Factual coherency of PLMs at EACL'24"
last_modified_at: 2024-03-20T16:20:02-05:00
categories:
  - blog
tags:
  - publication
  - natural language processing
---

When humans know "Rome is the capital of Italy", they also know "The capital of Italy is Rome". This means, if humans know a fact, they can be either queried for the subject or the object of the relation and retrieve the knowledge. We would expect pre-trained language models (PLMS) to also be able to do this. But, can they?

The [paper](https://aclanthology.org/2024.findings-eacl.155/) investigates the coherency of factual knowledge within pre-trained language models (PLMs). Highlighting a gap in PLMs' ability to accurately predict related facts in reverse, it points to a need for improved training methods.

The research emphasizes the potential of retrieval-based approaches, which significantly enhance factual coherency, aiming to make PLMs more reliable sources of factual information. Additionally, this work calls for developing pre-training objectives which explicitly optimize PLMs for more coherent knowledge states.

**Paper**
<ul class="key_pubs single_pub">
<li> {% reference Youssef2024_eacl_factual-coherency-PLMs %}</li>
</ul>

<iframe width="320" height="180"
        src="https://aclanthology.org/2024.findings-eacl.155.mp4"
        frameborder="0"
        allow="autoplay; encrypted-media"
        allowfullscreen></iframe>


